{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook example for MERRIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "from typing import Literal\n",
    "from pandas import DataFrame\n",
    "\n",
    "from merrin import MerrinLearner, Observation, MetabolicNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Selection of the instance\n",
    "instance: Literal['toy', 'core-regulated', 'large-scale'] = 'core-regulated'\n",
    "objective: str = 'Growth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Files describing the selected instance\n",
    "sbml: str = f'instances/{instance}/metabolic_network.sbml'\n",
    "pkn: str = f'instances/{instance}/pkn.txt'\n",
    "observations_json: str = f'instances/{instance}/timeseries_kft.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Solving modes\n",
    "# Select the projection mode:\n",
    "#   - `network`: enumerate all regulatory networks compatible with observations\n",
    "#   - `node`: for each node, enumerate all rules compatible with observations\n",
    "#   - `trace`: enumerate all classes of regulatory networks compatible\n",
    "#              with observations\n",
    "projection_mode: Literal['network', 'node', 'trace'] = 'network'\n",
    "# Only enumerate subset minimal rules or regulatory networks\n",
    "subset_minimal_optimisation: bool = False\n",
    "\n",
    "# ~ Solving parameters\n",
    "lpsolver: Literal['glpk', 'gurobi'] = 'glpk' # LP solver to use, default: `glpk`\n",
    "nbsol: int = 0 # 0 to enumerate all solution, else the nb of solution to enum\n",
    "timelimit: float = -1 # -1 if not timelimit, else the timelimit value in second\n",
    "max_gap: int = 10 # maximum number of timestep than can be added\n",
    "max_error: float = 0.1 # maximum error rate between observations and predictions\n",
    "max_clause: int = 20 # maximum number of clauses per rules in DNF\n",
    "\n",
    "# ~ Optional parameters\n",
    "display: bool = False # Display the learned rules/BNs at runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the Prior Knowlege Network file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_pkn: list[tuple[str, int, str]] = []\n",
    "with open(pkn, 'r', encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip()\n",
    "        u, s, v = line.split('\\t')\n",
    "        parsed_pkn.append((u, int(s), v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the JSONs file describing the observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations: list[Observation] = Observation.load_json(observations_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the SBML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn: MetabolicNetwork = MetabolicNetwork.read_sbml(sbml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERRIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner: MerrinLearner = MerrinLearner()\n",
    "learner.load_instance(mn, objective, parsed_pkn, observations)\n",
    "\n",
    "rules_df: DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Learn all the Boolean networks\n",
    "if projection_mode == 'network':\n",
    "    # ~ Learn the rule\n",
    "    bns: list[list[tuple[str, str]]] = learner.learn(\n",
    "        nbsol=nbsol, display=display, lp_solver=lpsolver, max_clause=max_clause,\n",
    "        max_error=max_error, max_gap=max_gap, timelimit=timelimit,\n",
    "        subsetmin=subset_minimal_optimisation\n",
    "    )\n",
    "    # ~ Post-processing: format the results into a pandas DataFrame\n",
    "    rules_df = DataFrame([dict(bn) for bn in bns]).fillna('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Learn all the rules per nodes of the PKN\n",
    "if projection_mode == 'node':\n",
    "    # ~ Learn the rule\n",
    "    rules: dict[str, list[str]] = learner.learn_per_node(\n",
    "        nbsol=nbsol, display=display, lp_solver=lpsolver, max_clause=max_clause,\n",
    "        max_error=max_error, max_gap=max_gap, timelimit=timelimit,\n",
    "        subsetmin=subset_minimal_optimisation\n",
    "    )\n",
    "    # ~ Post-processing: format the results into a pandas DataFrame\n",
    "    max_length = max(len(values) for _, values in rules.items())\n",
    "    padded_rules = {\n",
    "        col: values + [''] * (max_length - len(values))\n",
    "        for col, values in rules.items()\n",
    "    }\n",
    "    rules_df = DataFrame(padded_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Learn all the classes of BNs grouped per equivalent rFBA traces\n",
    "if projection_mode == 'trace':\n",
    "    # ~ Learn the rule\n",
    "    rules: list[dict[str, list[str]]] = learner.learn_per_trace(\n",
    "        nbsol=nbsol, display=display, lp_solver=lpsolver, max_clause=max_clause,\n",
    "        max_error=max_error, max_gap=max_gap, timelimit=timelimit,\n",
    "        subsetmin=subset_minimal_optimisation\n",
    "    )\n",
    "    # ~ Post-processing: format the results into a pandas DataFrame\n",
    "    format_rules: list[dict[str, str]] = [\n",
    "        { node: ';'.join(sorted(node_rules))\n",
    "         for node, node_rules in compress_bns.items()\n",
    "        }\n",
    "        for compress_bns in rules\n",
    "    ]\n",
    "    rules_df = DataFrame(format_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_df.sort_index(axis=1).sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
